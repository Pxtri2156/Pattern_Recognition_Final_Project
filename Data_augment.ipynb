{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data_augment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "12KkSQfrIRy-okHccxaMpeZL9oIdEb9wO",
      "authorship_tag": "ABX9TyPurNc6UQkyk7PxG/bEkGKD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pxtri2156/Pattern_Recognition_Final_Project/blob/add_argument_file/Data_augment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7k19smBgYNz"
      },
      "source": [
        "# Collect data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NS6Fy1FZAESI"
      },
      "source": [
        "cp -r /content/drive/MyDrive/Emotion_Speech_Recognition/RAW_DATASET/IEMOCAP/fix_IEMOCAP.zip fix_IEMOCAP.zip"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGEyhrUVAP3F"
      },
      "source": [
        "cp -r /content/drive/MyDrive/Emotion_Speech_Recognition/augument_file.zip augument_file.zip "
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X__PVTzoATdi"
      },
      "source": [
        "!unzip fix_IEMOCAP.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjboPxgxAWOS"
      },
      "source": [
        "!unzip augument_file.zip "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "my7IOX8YIG9M"
      },
      "source": [
        "cp -r /content/drive/MyDrive/Emotion_Speech_Recognition/RAW_DATASET/MELD/train_MELD.zip train_MELD.zip"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BTmwfTHS5bN"
      },
      "source": [
        "!unzip train_MELD.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIBSmRQGCNBe"
      },
      "source": [
        "mkdir data"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mWkYnVYCSmP"
      },
      "source": [
        "mv ang data"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFj7b6ZtCoG3"
      },
      "source": [
        "mv exc data"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvHX1_A4CqUP"
      },
      "source": [
        "mv fru data"
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Nqe6o2VCsFz"
      },
      "source": [
        "mv hap data"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42DIJyHFCt8z"
      },
      "source": [
        "mv neu data"
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZvjGp_xCvjw"
      },
      "source": [
        "mv sad data"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2OmgOx1jDfKM",
        "outputId": "27e9a6d5-6877-43d2-c13f-c4dc64e668bb"
      },
      "source": [
        "a = len(os.listdir('/content/data/ang'))\n",
        "b = len(os.listdir('/content/data/exc'))\n",
        "c = len(os.listdir('/content/data/fru'))\n",
        "d = len(os.listdir('/content/data/hap'))\n",
        "e = len(os.listdir('/content/data/neu'))\n",
        "f = len(os.listdir('/content/data/sad'))\n",
        "\n",
        "print(a + b + c + d + e + f)"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "49115\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o77tG1JgC4al"
      },
      "source": [
        "# root = 'fix_IEMOCAP'\n",
        "root_des = 'data'"
      ],
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJ5wrFVTUyMT"
      },
      "source": [
        "stt = 0\n",
        "stt_fail = 0"
      ],
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BnNg6Y7ST9L4",
        "outputId": "4c9c3691-6207-4a8c-93b3-44464a3e8797"
      },
      "source": [
        "for label in data:\n",
        "  for origin in data[label]:\n",
        "    name = origin.split('/')[-1]\n",
        "    destination = os.path.join(root_des,label,name)\n",
        "    # print(origin)\n",
        "    # print(destination)\n",
        "    # input()\n",
        "    if not os.path.exists(origin):\n",
        "      stt_fail += 1\n",
        "      continue\n",
        "    else:\n",
        "      stt += 1\n",
        "      shutil.move(origin, destination)\n",
        "  #   length += 1\n",
        "print(stt_fail)\n",
        "print(stt)"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "559\n",
            "18401\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4QsoaLwMkKA",
        "outputId": "901aa374-12b4-4e18-bbc5-dfa75b47e58f"
      },
      "source": [
        "a = len(os.listdir('/content/data/ang'))\n",
        "b = len(os.listdir('/content/data/exc'))\n",
        "c = len(os.listdir('/content/data/fru'))\n",
        "d = len(os.listdir('/content/data/hap'))\n",
        "e = len(os.listdir('/content/data/neu'))\n",
        "f = len(os.listdir('/content/data/sad'))\n",
        "\n",
        "print(a + b + c + d + e + f)"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "58036\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CliLLFPPYlzm"
      },
      "source": [
        "!zip -r data_merge.zip data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JeHE3wFPa_ft"
      },
      "source": [
        "!mv /content/data_merge.zip /content/drive/MyDrive/Emotion_Speech_Recognition/"
      ],
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bsyruKLhgK5-"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsK2c1OkcGmq"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBPTr3RMcSuj"
      },
      "source": [
        "root = '/content/data'"
      ],
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ya7zB3f6cMop"
      },
      "source": [
        "image_id = []\n",
        "lbs = []"
      ],
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCpg3mYncboh"
      },
      "source": [
        "labels = os.listdir(root)\n",
        "\n",
        "for lb in labels:\n",
        "  path_imgs = os.listdir(root+'/' +lb)\n",
        "\n",
        "  for path in path_imgs:\n",
        "    image_id.append(os.path.join(lb,path))\n",
        "    lbs.append(lb)"
      ],
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23RTnYZsdbLD"
      },
      "source": [
        "df = pd.DataFrame(data=image_id,columns=['image_id'])\n",
        "df['class'] = lbs\n",
        "df.to_csv(\"data_aug.csv\", index=False)"
      ],
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YybLwsElei-j"
      },
      "source": [
        "# Split fold"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7fNTBvbeybz"
      },
      "source": [
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import StratifiedKFold"
      ],
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enhbRDZpemMk"
      },
      "source": [
        "train = pd.read_csv(\"data_aug.csv\")\n",
        "   \n",
        "train.reset_index(inplace=True)\n",
        "\n",
        "for i in range(10):\n",
        "  train = shuffle(train)\n",
        "skf  = StratifiedKFold(n_splits = 5)\n",
        "\n",
        "train['fold'] = 0\n",
        "for fold, (train_idx, val_idx) in enumerate(skf.split(X=train[\"index\"], y=train[\"class\"])):\n",
        "    train.loc[val_idx, 'fold'] = fold\n",
        "\n",
        "train.to_csv(\"skf5folds.csv\", index=False)"
      ],
      "execution_count": 161,
      "outputs": []
    }
  ]
}